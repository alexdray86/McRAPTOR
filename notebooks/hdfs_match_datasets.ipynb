{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match datasets \n",
    "\n",
    "### Name your spark application as `GASPAR_final` or `GROUP_NAME_final`.\n",
    "\n",
    "<div class='alert alert-info'><b>Any application without a proper name would be promptly killed.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'lgptguys_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8983</td><td>application_1589299642358_3520</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3520/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3520_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9081</td><td>application_1589299642358_3641</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3641/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3641_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9084</td><td>application_1589299642358_3644</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3644/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3644_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9098</td><td>application_1589299642358_3660</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3660/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3660_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9112</td><td>application_1589299642358_3675</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3675/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3675_01_000005/ebouille\">Link</a></td><td></td></tr><tr><td>9121</td><td>application_1589299642358_3684</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3684/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3684_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9130</td><td>application_1589299642358_3694</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3694/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3694_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9145</td><td>application_1589299642358_3710</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3710/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3710_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9152</td><td>application_1589299642358_3716</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3716/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3716_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9153</td><td>application_1589299642358_3717</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3717/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3717_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9156</td><td>application_1589299642358_3721</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3721/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3721_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9157</td><td>application_1589299642358_3722</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3722/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3722_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9159</td><td>application_1589299642358_3724</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3724/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3724_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9160</td><td>application_1589299642358_3725</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3725/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3725_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9163</td><td>application_1589299642358_3729</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3729/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3729_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9164</td><td>application_1589299642358_3730</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3730/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3730_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9167</td><td>application_1589299642358_3733</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3733/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3733_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9168</td><td>application_1589299642358_3734</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3734/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3734_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9170</td><td>application_1589299642358_3737</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3737/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3737_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9171</td><td>application_1589299642358_3738</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3738/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3738_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9173</td><td>application_1589299642358_3740</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3740/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3740_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9174</td><td>application_1589299642358_3741</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3741/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3741_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9175</td><td>application_1589299642358_3742</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3742/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3742_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9176</td><td>application_1589299642358_3743</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3743/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3743_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9177</td><td>application_1589299642358_3744</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3744/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3744_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9179</td><td>application_1589299642358_3746</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3746/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3746_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"lgptguys_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9180</td><td>application_1589299642358_3747</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3747/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3747_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "unknown magic command '%spark'\n",
      "UnknownMagic: unknown magic command '%spark'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "%%spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Variable named username not found.\n"
     ]
    }
   ],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from geopy.distance import great_circle\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType,LongType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TimeTable curated data\n",
    "\n",
    "contains only stops / trips in a 15km range from Zurich HB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data with stop_id of interest\n",
    "stop_times = spark.read.csv('data/lgpt_guys/stop_times_final_cyril.csv', header = True)\n",
    "stops_15km = stop_times.select(col('stop_id_general')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the [SBB actual data](https://opentransportdata.swiss/en/dataset/istdaten) in ORC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['betriebstag', 'fahrt_bezeichner', 'betreiber_id', 'betreiber_abk', 'betreiber_name', 'produkt_id', 'linien_id', 'linien_text', 'umlauf_id', 'verkehrsmittel_text', 'zusatzfahrt_tf', 'faellt_aus_tf', 'bpuic', 'haltestellen_name', 'ankunftszeit', 'an_prognose', 'an_prognose_status', 'abfahrtszeit', 'ab_prognose', 'ab_prognose_status', 'durchfahrt_tf']"
     ]
    }
   ],
   "source": [
    "sbb = spark.read.orc('/data/sbb/orc/istdaten')\n",
    "sbb.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset SBB data\n",
    "\n",
    "We take only stop_id in 15 km range from Zurich HB - Then, we want to write an intermidate table to avoid doing the computation on the whole SBB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Used to subset sbb table based on stop_id from stops_15km\n",
    "stop_id  = stops_15km.select('stop_id_general').collect()\n",
    "stop_idx = [item.stop_id_general for item in stop_id]\n",
    "\n",
    "# Make the subset dataframe\n",
    "sbb_filt = sbb.filter( sbb['bpuic'].isin(stop_idx) )\\\n",
    "              .select('fahrt_bezeichner','haltestellen_name', 'produkt_id',\\\n",
    "                      'ankunftszeit', 'abfahrtszeit', 'betriebstag',\\\n",
    "                      col('bpuic').alias('stop_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write the resulting subset. This is important to avoid working on the whole dataset and only on a subset of it, which makes every run much faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save\n",
    "username = 'acoudray'\n",
    "sbb_filt.write.format(\"orc\").save(\"/user/{}/sbb_filt2.orc\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these are the files previously added to /user/{}/ :\n",
    "- `sbb_filt2.orc` : every day with stations < 15km (Cyril final version)\n",
    "- `sbb_filt.orc` : every day with stations < 15km\n",
    "- `sbb_subTime.orc` : schedule of May 13-17, 2019, stations < 15km\n",
    "- `sbb_subTime2.orc` : schedule of May 13-17, 2019, stations < 15km (Cyril final version)\n",
    "- `sbb_subTime3.orc` : schedule of May 13-17, 2019, stations < 15km (Cyril final version)\n",
    "- `sbb_oneday.orc` : May 13th 2019 only, stations < 15km, `linien_id` field added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding stop_id between two datasets \n",
    "\n",
    "We first look at the station names in timetable dataset. Stop_id can be given in multiple formats :\n",
    "- `8502186` : the format defining the stop itself, which matches sbb `bpuic` field\n",
    "\n",
    "We will call the 3 next ones __Special cases__ throughout the notebook :\n",
    "- `8502186:0:1` or `8502186:0:2` : The individual platforms are separated by “:”. A “platform” can also be a platform+sectors (e.g. “8500010:0:7CD”).\n",
    "- `8502186P` : All the stops have a common “parent” “8500010P”.\n",
    "- `8502186:0:Bfpl` : if the RBS uses it for rail replacement buses.\n",
    "\n",
    "source : [timetable cookbook](https://opentransportdata.swiss/en/cookbook/gtfs/), section stops.txt \n",
    "\n",
    "In the sbb actual_data we find equivalent to stop_id in its first format defining the station without platform information, in its `bpuic` field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get corresponding trip_id between two datasets \n",
    "\n",
    "In sbb dataset, the trip ids are defined by `FAHRT_BEZEICHNER` field and in timetable `trip_id`. We will use corresponding station_id and arrival_times in order to get corresponding trip_id. Our goal is to find a match in sbb dataset for _timetable_ trips (and not the other way around). So we will focus on getting this assymetrical correspondance table. \n",
    "\n",
    "These labels will be used to differentiate 3 different ways to compute probabilities :\n",
    "- __One-to-one__ we find a clear match : we use distribution of delays on weekdays for a given trip/station_id based on all past sbb data. \n",
    "- __One-to-many__ we find multiple matches : Matches are aggregated together in the final distribution table\n",
    "- __One-to-none__ we find no match : as described later, we will use delay distribution of similar trip (sharing stop_id, transport type and hour) to infer the delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Timetable dataset__ \n",
    "\n",
    "We first load _timetable_ with curated trip_id, in a 15km radius from Zurich HB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260459\n",
      "+-----------+---------------+----------------------+-------+------------+--------------+-------------+------------------------+----------------+----------------+---------------+---------------+------------+--------------------+---------+----------+--------+----------+---------------------------+\n",
      "|route_id   |stop_id_general|trip_id               |stop_id|arrival_time|departure_time|stop_sequence|stop_name               |stop_lat        |stop_lon        |trip_headsign  |trip_short_name|direction_id|departure_first_stop|route_int|stop_count|stop_int|route_desc|monotonically_increasing_id|\n",
      "+-----------+---------------+----------------------+-------+------------+--------------+-------------+------------------------+----------------+----------------+---------------+---------------+------------+--------------------+---------+----------+--------+----------+---------------------------+\n",
      "|26-46-j19-1|8591371        |742.TA.26-46-j19-1.8.R|8591371|18:06:00    |18:06:00      |13           |Zürich, Singlistrasse   |47.4051109214132|8.49349016415681|Zürich, Rütihof|2524           |1           |17:48:00            |1363     |18        |879     |Bus       |1632087572480              |\n",
      "|26-46-j19-1|8591358        |742.TA.26-46-j19-1.8.R|8591358|18:07:00    |18:07:00      |14           |Zürich, Segantinistrasse|47.4074455475966|8.48996876824257|Zürich, Rütihof|2524           |1           |17:48:00            |1363     |18        |1025    |Bus       |1632087572481              |\n",
      "|26-46-j19-1|8591158        |742.TA.26-46-j19-1.8.R|8591158|18:08:00    |18:08:00      |15           |Zürich, Giblenstrasse   |47.4107284405996|8.485953298922  |Zürich, Rütihof|2524           |1           |17:48:00            |1363     |18        |704     |Bus       |1632087572482              |\n",
      "+-----------+---------------+----------------------+-------+------------+--------------+-------------+------------------------+----------------+----------------+---------------+---------------+------------+--------------------+---------+----------+--------+----------+---------------------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "# Load data \n",
    "stop_times = spark.read.csv('data/lgpt_guys/stop_times_final_cyril.csv', header = True)\n",
    "\n",
    "# Print number of lines and show\n",
    "print stop_times.count()\n",
    "stop_times.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------+------------+--------------+\n",
      "|trip_id               |stop_id|arrival_time|departure_time|\n",
      "+----------------------+-------+------------+--------------+\n",
      "|742.TA.26-46-j19-1.8.R|8591371|06:06       |06:06         |\n",
      "|742.TA.26-46-j19-1.8.R|8591358|06:07       |06:07         |\n",
      "|742.TA.26-46-j19-1.8.R|8591158|06:08       |06:08         |\n",
      "|742.TA.26-46-j19-1.8.R|8576241|06:09       |06:09         |\n",
      "|742.TA.26-46-j19-1.8.R|8591155|06:10       |06:10         |\n",
      "+----------------------+-------+------------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Make the subset dataframe\n",
    "stop_times_format = stop_times\\\n",
    "                   .select('trip_id', col('stop_id_general').alias('stop_id'), \n",
    "                          unix_timestamp(stop_times.arrival_time, 'HH:mm:ss')\\\n",
    "                          .alias('arrival_time_ut'),\\\n",
    "                          unix_timestamp(stop_times.departure_time, 'HH:mm:ss')\\\n",
    "                          .alias('departure_time_ut') )\\\n",
    "                   .select('trip_id', 'stop_id', \n",
    "                            from_unixtime('arrival_time_ut')\\\n",
    "                            .alias('arrival_time_dty'),\n",
    "                            from_unixtime('departure_time_ut')\\\n",
    "                            .alias('departure_time_dty'))\\\n",
    "                   .select('trip_id', 'stop_id', \n",
    "                             date_format('arrival_time_dty', 'hh:mm')\\\n",
    "                             .alias('arrival_time'),\n",
    "                             date_format('departure_time_dty', 'hh:mm')\\\n",
    "                            .alias('departure_time'))\\\n",
    "                   .na.fill(\"unknown\")\n",
    "\n",
    "\n",
    "stop_times_format.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reformated `arrival_time` and `departure_time` to get it in `hh:mm` format. \n",
    "\n",
    "Here is an example of a single trip_id for an Eurocity and another one for an Intercity train : they have very few stops in the 15km perimeter around Zurich HB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------+------------+--------------+\n",
      "|trip_id                |stop_id|arrival_time|departure_time|\n",
      "+-----------------------+-------+------------+--------------+\n",
      "|35.TA.40-5-Y-j19-1.33.H|8503000|06:52       |07:02         |\n",
      "|35.TA.40-5-Y-j19-1.33.H|8503016|07:12       |07:14         |\n",
      "+-----------------------+-------+------------+--------------+"
     ]
    }
   ],
   "source": [
    "EC_trip_id = '35.TA.40-5-Y-j19-1.33.H'\n",
    "\n",
    "stop_times_format.filter(stop_times_format['trip_id'] == EC_trip_id)\\\n",
    "                 .show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+------------+--------------+\n",
      "|trip_id            |stop_id|arrival_time|departure_time|\n",
      "+-------------------+-------+------------+--------------+\n",
      "|6.TA.16-5-j19-1.6.R|8503000|07:30       |07:39         |\n",
      "|6.TA.16-5-j19-1.6.R|8503006|07:45       |07:46         |\n",
      "|6.TA.16-5-j19-1.6.R|8503016|07:51       |07:53         |\n",
      "+-------------------+-------+------------+--------------+"
     ]
    }
   ],
   "source": [
    "IC_trip_id = '6.TA.16-5-j19-1.6.R'\n",
    "\n",
    "stop_times_format.filter(stop_times_format['trip_id'] == IC_trip_id)\\\n",
    "                 .show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have _timetable_ trip_id, the stop_id as defined above, and arrival/departure time. The idea is to match these information with the ones we have in sbb dataset. Stop_id and time match between both datasets.\n",
    "\n",
    " __SBB dataset__\n",
    " \n",
    "We will subset sbb dataset to get only the 13th of May in sbb dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+----------------+----------------+-----------+-------+\n",
      "|fahrt_bezeichner|haltestellen_name|produkt_id|    ankunftszeit|    abfahrtszeit|betriebstag|stop_id|\n",
      "+----------------+-----------------+----------+----------------+----------------+-----------+-------+\n",
      "|    85:11:10:002|        Zürich HB|       Zug|12.10.2018 21:51|                | 12.10.2018|8503000|\n",
      "| 85:11:10293:004|        Zürich HB|       Zug|                |13.10.2018 00:25| 12.10.2018|8503000|\n",
      "| 85:11:10293:004| Zürich Flughafen|       Zug|13.10.2018 00:34|13.10.2018 00:35| 12.10.2018|8503016|\n",
      "| 85:11:10536:004|        Zürich HB|       Zug|                |12.10.2018 20:03| 12.10.2018|8503000|\n",
      "| 85:11:10537:006|        Zürich HB|       Zug|12.10.2018 21:59|                | 12.10.2018|8503000|\n",
      "+----------------+-----------------+----------+----------------+----------------+-----------+-------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "username='acoudray'\n",
    "sbb_subTime = spark.read.orc(\"/user/{}/sbb_filt2.orc\".format(username))\n",
    "\n",
    "sbb_subTime.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first convert time in string format 'hh:mm', same than in timetable. We fill null with 'unknown' string (to be able to catch it) and we format `fahrt_bezeichner` to remove extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------+--------------+\n",
      "|fahrt_bezeichner|stop_id|arrival_time|departure_time|\n",
      "+----------------+-------+------------+--------------+\n",
      "|85:11:10:002    |8503000|09:51       |unknown       |\n",
      "|85:11:10293:004 |8503000|unknown     |12:25         |\n",
      "|85:11:10293:004 |8503016|12:34       |12:35         |\n",
      "|85:11:10536:004 |8503000|unknown     |08:03         |\n",
      "|85:11:10537:006 |8503000|09:59       |unknown       |\n",
      "+----------------+-------+------------+--------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Make the subset dataframe\n",
    "sbb_filt = sbb_subTime.select('fahrt_bezeichner', 'stop_id',\\\n",
    "                          unix_timestamp(sbb_subTime.ankunftszeit, 'dd.MM.yyyy HH:mm')\\\n",
    "                          .alias('arrival_time_ut'),\\\n",
    "                          unix_timestamp(sbb_subTime.abfahrtszeit, 'dd.MM.yyyy HH:mm')\\\n",
    "                          .alias('departure_time_ut') )\\\n",
    "                   .select('fahrt_bezeichner', 'stop_id', \n",
    "                            from_unixtime('arrival_time_ut')\\\n",
    "                            .alias('arrival_time_dty'),\n",
    "                            from_unixtime('departure_time_ut')\\\n",
    "                            .alias('departure_time_dty'))\\\n",
    "                   .select('fahrt_bezeichner', 'stop_id', \n",
    "                             date_format('arrival_time_dty', 'hh:mm')\\\n",
    "                             .alias('arrival_time'),\n",
    "                             date_format('departure_time_dty', 'hh:mm')\\\n",
    "                            .alias('departure_time'))\\\n",
    "                   .na.fill(\"unknown\")\n",
    "\n",
    "sbb_filt.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a control Eurocity / Intercity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+------------+--------------+\n",
      "|fahrt_bezeichner|stop_id|arrival_time|departure_time|\n",
      "+----------------+-------+------------+--------------+\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "|85:11:2281:004  |8503000|06:52       |07:02         |\n",
      "|85:11:2281:004  |8503016|07:12       |07:14         |\n",
      "+----------------+-------+------------+--------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "EC_trip_sbb = '85:11:2281:004'\n",
    "\n",
    "sbb_filt.filter(sbb_filt['fahrt_bezeichner'] == EC_trip_sbb)\\\n",
    "                 .show(20,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one match per day, but they all share the same `fahrt_bezeichner`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Join two datasets on stop_id and time__\n",
    "\n",
    "We can now create a joined table using timetable-derived `stop_time` and sbb-derived `sbb_filt`. We use `stop_id`, `arrival_time` and `departure_time` to merge tables using `join` function. The idea is to compare the trip_id from both dataset - they should end up on the same line after the join. We use join with _left_outer_ so that we can only have _null_ values on the sbb side (assymetrical join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------+\n",
      "|trip_id                |fahrt_bezeichner|\n",
      "+-----------------------+----------------+\n",
      "|62.TA.1-17-A-j19-1.5.H |85:31:511:000   |\n",
      "|62.TA.1-17-A-j19-1.5.H |85:31:571:000   |\n",
      "|62.TA.1-17-A-j19-1.5.H |85:31:511:002   |\n",
      "|62.TA.1-17-A-j19-1.5.H |85:31:571:002   |\n",
      "|5.TA.30-57-Y-j19-1.1.H |null            |\n",
      "|29.TA.30-57-Y-j19-1.1.H|null            |\n",
      "|152.TA.26-14-j19-1.32.R|null            |\n",
      "|224.TA.26-14-j19-1.43.H|85:11:19427:001 |\n",
      "|224.TA.26-14-j19-1.43.H|85:11:19475:001 |\n",
      "|224.TA.26-14-j19-1.43.H|85:11:31475:005 |\n",
      "+-----------------------+----------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "joined_trip_table = stop_times_format.join(sbb_filt,\\\n",
    "                                           on=['stop_id', 'arrival_time', 'departure_time'],\\\n",
    "                                           how='left_outer')\\\n",
    "                                     .select('stop_id', 'arrival_time', 'departure_time',\n",
    "                                             'trip_id', 'fahrt_bezeichner')\\\n",
    "                                     .distinct()\\\n",
    "                                     .select('trip_id', 'fahrt_bezeichner')\n",
    "                                     #.select('trip_id', col('fahrt_bezeichner_format').alias('fahrt_bezeichner'))\n",
    "joined_trip_table.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the raw results of the intersection. Note that we used a `distinct()` to avoid having multiple lines corresponding to multiple days. Each line must be a unqiue combination of `trip_id` x `stop_id`, no matter which day it is. \n",
    "\n",
    "Now we can count how many stops (with same time) are shared between trip_id from _timetable_ and _sbb_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------+-----+\n",
      "|trip_id                  |fahrt_bezeichner      |count|\n",
      "+-------------------------+----------------------+-----+\n",
      "|224.TA.26-14-j19-1.43.H  |85:11:19427:001       |13   |\n",
      "|1250.TA.26-67-j19-1.2.H  |85:849:248315-13067-1 |8    |\n",
      "|233.TA.26-24-j19-1.123.H |85:11:20419:001       |12   |\n",
      "|56.TA.79-10-B-j19-1.3.H  |85:78:12823:002       |4    |\n",
      "|12.TA.26-816-j19-1.1.H   |85:838:401979-17850-1 |4    |\n",
      "|12.TA.26-816-j19-1.1.H   |85:838:298342-17850-1 |4    |\n",
      "|12.TA.26-816-j19-1.1.H   |85:838:232343-10850-1 |4    |\n",
      "|603.TA.26-33E-j19-1.4.H  |85:849:414098-12412-1 |10   |\n",
      "|603.TA.26-33E-j19-1.4.H  |85:849:521451-28031-1 |1    |\n",
      "|3683.TA.26-8-C-j19-1.27.H|85:3849:590678-05011-1|4    |\n",
      "+-------------------------+----------------------+-----+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "joined_trip_count = joined_trip_table.groupBy(\"trip_id\", \"fahrt_bezeichner\")\\\n",
    "                                    .count()\n",
    "\n",
    "joined_trip_count.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write intermediate table to save results and get better performance for next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_trip_count.write.csv('data/lgpt_guys/joined_trip_count_6_full.csv', \\\n",
    "                            header = True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-load cached data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_trip_count = spark.read.csv('data/lgpt_guys/joined_trip_count_6_full.csv', \\\n",
    "                            header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use a threshold to only get correspondances between `trip_id` that share a certain number of `stop_id` at the same `departure_time` / `arrival_time`.  We decided to use 2 as a minimum number of match needed -> this was required to be able to get InterCity / InterRegio trains, which have few stops in the 15km perimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------------------+-----+\n",
      "|trip_id                   |fahrt_bezeichner      |count|\n",
      "+--------------------------+----------------------+-----+\n",
      "|89.TA.26-721-j19-1.3.H    |85:773:778860-04720-1 |7    |\n",
      "|217.TA.1-17-A-j19-1.17.H  |85:31:987:000         |12   |\n",
      "|1890.TA.26-11-A-j19-1.27.R|85:3849:137108-21011-1|25   |\n",
      "|1612.TA.26-10-j19-1.11.R  |85:3849:617087-24010-1|19   |\n",
      "|113.TA.26-131-j19-1.6.R   |85:807:473534-31131-1 |3    |\n",
      "|113.TA.26-131-j19-1.6.R   |85:807:620139-12131-1 |3    |\n",
      "|124.TA.26-131-j19-1.7.R   |85:807:277454-25131-1 |6    |\n",
      "|59.TA.26-842-j19-1.1.H    |85:838:283297-14850-1 |5    |\n",
      "|59.TA.26-842-j19-1.1.H    |85:838:83400-11850-2  |5    |\n",
      "|38.TA.26-660-j19-1.5.H    |85:882:847761-15101-1 |6    |\n",
      "+--------------------------+----------------------+-----+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "cutoff_min_overlap = 2\n",
    "\n",
    "joined_trip_atL2 = joined_trip_count.filter(col('count') >= cutoff_min_overlap )\n",
    "\n",
    "joined_trip_atL2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table indicates how many stop_id / departure_time / arrival_time were identical between `trip_id` (_timetable_ data) and `fahrt_bezeichner` (sbb data). The idea is to take every trip_id with more than X matches between the two datasets.\n",
    "\n",
    "We write a little summary of how many trip_id are found in the translation table :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the join is :                           921476\n",
      "number of unique timetable trip_id :            19135\n",
      "number of unique sbb trip_id (fahrtbezeichner): 601214"
     ]
    }
   ],
   "source": [
    "print \"size of the join is :                           {}\".format(joined_trip_atL2.count())\n",
    "print \"number of unique timetable trip_id :            {}\".format(joined_trip_atL2.select('trip_id').distinct().count())\n",
    "print \"number of unique sbb trip_id (fahrtbezeichner): {}\".format(joined_trip_atL2.select('fahrt_bezeichner').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results in csv format in general folder data/lgpt_guys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_trip_atL2.write.csv('data/lgpt_guys/match_datasets_translation.csv', header = True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation - Check a few exemple trains__\n",
    "\n",
    "Can we find these \n",
    "\n",
    "We will check \n",
    "- an eurocity train : trip_id = `35.TA.40-5-Y-j19-1.33.H` \n",
    "- and an Intercity  : trip_id = `6.TA.16-5-j19-1.6.R`\n",
    "\n",
    "They should have 2/3 stop_id each :\n",
    "- EC : `8503000` and `8503016` \n",
    "- IC : `8503000`, `8503006` and `8503016`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+-----+\n",
      "|            trip_id|fahrt_bezeichner|count|\n",
      "+-------------------+----------------+-----+\n",
      "|6.TA.16-5-j19-1.6.R|  85:11:1533:001|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:31509:004|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30509:005|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30533:006|    3|\n",
      "|6.TA.16-5-j19-1.6.R|  85:11:1509:001|    3|\n",
      "|6.TA.16-5-j19-1.6.R|  85:11:1509:002|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30509:002|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:71533:001|    2|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:31533:001|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30233:008|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:71533:007|    2|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30533:005|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30533:001|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:10409:002|    2|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30509:006|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:10433:002|    2|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30033:003|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:71509:002|    2|\n",
      "|6.TA.16-5-j19-1.6.R|  85:11:1533:002|    3|\n",
      "|6.TA.16-5-j19-1.6.R| 85:11:30209:006|    3|\n",
      "+-------------------+----------------+-----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "IC_trip_id = '6.TA.16-5-j19-1.6.R'\n",
    "joined_trip_atL2.filter(joined_trip_atL2.trip_id == IC_trip_id).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|             trip_id|fahrt_bezeichner|count|\n",
      "+--------------------+----------------+-----+\n",
      "|35.TA.40-5-Y-j19-...| 85:11:30191:004|    2|\n",
      "|35.TA.40-5-Y-j19-...|  85:11:2281:004|    2|\n",
      "|35.TA.40-5-Y-j19-...| 85:11:30591:015|    2|\n",
      "|35.TA.40-5-Y-j19-...|   85:11:191:001|    2|\n",
      "+--------------------+----------------+-----+"
     ]
    }
   ],
   "source": [
    "EC_trip_id = '35.TA.40-5-Y-j19-1.33.H'\n",
    "joined_trip_atL2.filter(joined_trip_atL2.trip_id == EC_trip_id).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
